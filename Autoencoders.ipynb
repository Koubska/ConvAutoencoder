{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection of all autoencoders in one place. \n",
    "# Copy and paste the code from here to the respective notebook to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 17:24:57.602917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 17:24:57.770109: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 17:24:57.770123: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 17:24:58.478041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 17:24:58.478084: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 17:24:58.478089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quiver_engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msubprocess\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_model\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mquiver_engine\u001b[39;00m \u001b[39mimport\u001b[39;00m server\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'quiver_engine'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_model_remediation as tfmr\n",
    "import sklearn\n",
    "from tensorflow.keras import layers, losses, metrics\n",
    "from keras.layers import Input, Dense, UpSampling1D, Conv1D, AveragePooling1D, MaxPooling1D, Flatten, Reshape, Dropout, Conv1DTranspose, ZeroPadding1D, Cropping1D, Conv1DTranspose\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compression_rate(init_shape : tuple, latent_shape : tuple) : \n",
    "    return (init_shape[1] * init_shape[2]) / (latent_shape[1] * latent_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_width = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Successfully set GPU memory limit to 1024 MB\n",
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Restrict TensorFlow for a certain amount of gpu memory \n",
    "#I needed to add this here because tensorflow was just using all of my gpu memory and freezing my PC\n",
    "gpu_memory_limit = 1024*1 # 12 GB\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=gpu_memory_limit)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    print(\"Successfully set GPU memory limit to\", gpu_memory_limit, \"MB\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "  else : \n",
    "    print(\"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate:  2.0\n"
     ]
    }
   ],
   "source": [
    "encoder_seq = Sequential([\n",
    "    Input(shape=(neural_network_width,1), name=\"input\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_1\"),\n",
    "    Conv1D(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_2\"),\n",
    "    Conv1D(filters=4, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_3\"),\n",
    "], name=\"encoder\")\n",
    "\n",
    "decoder_seq = Sequential([\n",
    "    Input(shape=(encoder_seq.output.shape[1], encoder_seq.output.shape[2])),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_1\"),\n",
    "    Conv1DTranspose(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_2\"),\n",
    "    Conv1DTranspose(filters=1, kernel_size=8, strides=2, activation='sigmoid',  padding='same', name=\"decoder_3\"),\n",
    "], name=\"decoder\")\n",
    "\n",
    "autoencoder = Sequential([\n",
    "    encoder_seq,\n",
    "    decoder_seq\n",
    "], name=\"autoencoder\")\n",
    "\n",
    "print(\"Compression rate: \", get_compression_rate(encoder_seq.input.shape, encoder_seq.output.shape))\n",
    "server.launch(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate:  4.0\n"
     ]
    }
   ],
   "source": [
    "encoder_seq = Sequential([\n",
    "    Input(shape=(neural_network_width,1), name=\"input\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_1\"),\n",
    "    Conv1D(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_2\"),\n",
    "    Conv1D(filters=2, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_3\"),\n",
    "], name=\"encoder\")\n",
    "\n",
    "decoder_seq = Sequential([\n",
    "    Input(shape=(encoder_seq.output.shape[1], encoder_seq.output.shape[2])),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_1\"),\n",
    "    Conv1DTranspose(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_2\"),\n",
    "    Conv1DTranspose(filters=1, kernel_size=8, strides=2, activation='sigmoid',  padding='same', name=\"decoder_3\"),\n",
    "], name=\"decoder\")\n",
    "\n",
    "autoencoder = Sequential([\n",
    "    encoder_seq,\n",
    "    decoder_seq\n",
    "], name=\"autoencoder\")\n",
    "\n",
    "print(\"Compression rate: \", get_compression_rate(encoder_seq.input.shape, encoder_seq.output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate:  8.0\n"
     ]
    }
   ],
   "source": [
    "encoder_seq = Sequential([\n",
    "    Input(shape=(neural_network_width,1), name=\"input\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_1\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_2\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_3\"),\n",
    "    Conv1D(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_4\"),\n",
    "    Conv1D(filters=4, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_5\"),\n",
    "], name=\"encoder\")\n",
    "\n",
    "decoder_seq = Sequential([\n",
    "    Input(shape=(encoder_seq.output.shape[1], encoder_seq.output.shape[2])),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_1\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_2\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_3\"),\n",
    "    Conv1DTranspose(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_4\"),\n",
    "    Conv1DTranspose(filters=1, kernel_size=8, strides=2, activation='sigmoid',  padding='same', name=\"decoder_5\"),\n",
    "], name=\"decoder\")\n",
    "\n",
    "autoencoder = Sequential([\n",
    "    encoder_seq,\n",
    "    decoder_seq\n",
    "], name=\"autoencoder\")\n",
    "\n",
    "print(\"Compression rate: \", get_compression_rate(encoder_seq.input.shape, encoder_seq.output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate:  16.0\n"
     ]
    }
   ],
   "source": [
    "encoder_seq = Sequential([\n",
    "    Input(shape=(neural_network_width,1), name=\"input\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_1\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_2\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_3\"),\n",
    "    Conv1D(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_4\"),\n",
    "    Conv1D(filters=2, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_5\"),\n",
    "], name=\"encoder\")\n",
    "\n",
    "decoder_seq = Sequential([\n",
    "    Input(shape=(encoder_seq.output.shape[1], encoder_seq.output.shape[2])),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_1\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_2\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_3\"),\n",
    "    Conv1DTranspose(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_4\"),\n",
    "    Conv1DTranspose(filters=1, kernel_size=8, strides=2, activation='sigmoid',  padding='same', name=\"decoder_5\"),\n",
    "], name=\"decoder\")\n",
    "\n",
    "autoencoder = Sequential([\n",
    "    encoder_seq,\n",
    "    decoder_seq\n",
    "], name=\"autoencoder\")\n",
    "\n",
    "print(\"Compression rate: \", get_compression_rate(encoder_seq.input.shape, encoder_seq.output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate:  32.0\n"
     ]
    }
   ],
   "source": [
    "encoder_seq = Sequential([\n",
    "    Input(shape=(neural_network_width,1), name=\"input\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_1\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_2\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_3\"),\n",
    "    Conv1D(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_4\"),\n",
    "    Conv1D(filters=4, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_5\"),\n",
    "    Conv1D(filters=2, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_6\"),\n",
    "], name=\"encoder\")\n",
    "\n",
    "decoder_seq = Sequential([\n",
    "    Input(shape=(encoder_seq.output.shape[1], encoder_seq.output.shape[2])),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_1\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_2\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_3\"),\n",
    "    Conv1DTranspose(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_4\"),\n",
    "    Conv1DTranspose(filters=4, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_5\"),\n",
    "    Conv1DTranspose(filters=1, kernel_size=8, strides=2, activation='sigmoid',  padding='same', name=\"decoder_6\"),\n",
    "], name=\"decoder\")\n",
    "\n",
    "autoencoder = Sequential([\n",
    "    encoder_seq,\n",
    "    decoder_seq\n",
    "], name=\"autoencoder\")\n",
    "\n",
    "print(\"Compression rate: \", get_compression_rate(encoder_seq.input.shape, encoder_seq.output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate:  64.0\n"
     ]
    }
   ],
   "source": [
    "encoder_seq = Sequential([\n",
    "    Input(shape=(neural_network_width,1), name=\"input\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_1\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_2\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_3\"),\n",
    "    Conv1D(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_4\"),\n",
    "    Conv1D(filters=4, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_5\"),\n",
    "    Conv1D(filters=1, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_6\"),\n",
    "], name=\"encoder\")\n",
    "\n",
    "decoder_seq = Sequential([\n",
    "    Input(shape=(encoder_seq.output.shape[1], encoder_seq.output.shape[2])),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_1\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_2\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_3\"),\n",
    "    Conv1DTranspose(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_4\"),\n",
    "    Conv1DTranspose(filters=4, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_5\"),\n",
    "    Conv1DTranspose(filters=1, kernel_size=8, strides=2, activation='sigmoid',  padding='same', name=\"decoder_6\"),\n",
    "], name=\"decoder\")\n",
    "\n",
    "autoencoder = Sequential([\n",
    "    encoder_seq,\n",
    "    decoder_seq\n",
    "], name=\"autoencoder\")\n",
    "\n",
    "print(\"Compression rate: \", get_compression_rate(encoder_seq.input.shape, encoder_seq.output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate:  128.0\n"
     ]
    }
   ],
   "source": [
    "encoder_seq = Sequential([\n",
    "    Input(shape=(neural_network_width,1), name=\"input\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_1\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_2\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_3\"),\n",
    "    Conv1D(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_4\"),\n",
    "    Conv1D(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_5\"),\n",
    "    Conv1D(filters=4, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_6\"),\n",
    "    Conv1D(filters=1, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"encoder_7\"),\n",
    "], name=\"encoder\")\n",
    "\n",
    "decoder_seq = Sequential([\n",
    "    Input(shape=(encoder_seq.output.shape[1], encoder_seq.output.shape[2])),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_1\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_2\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_3\"),\n",
    "    Conv1DTranspose(filters=16, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_4\"),\n",
    "    Conv1DTranspose(filters=8, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_5\"),\n",
    "    Conv1DTranspose(filters=4, kernel_size=8, strides=2, activation='leaky_relu',  padding='same', name=\"decoder_6\"),\n",
    "    Conv1DTranspose(filters=1, kernel_size=8, strides=2, activation='sigmoid',  padding='same', name=\"decoder_7\"),\n",
    "], name=\"decoder\")\n",
    "\n",
    "autoencoder = Sequential([\n",
    "    encoder_seq,\n",
    "    decoder_seq\n",
    "], name=\"autoencoder\")\n",
    "\n",
    "print(\"Compression rate: \", get_compression_rate(encoder_seq.input.shape, encoder_seq.output.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
